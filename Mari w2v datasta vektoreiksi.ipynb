{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class': 'pos', 'text': 'This film was just absolutly brilliant. It actually made me think. During the whole movie I was confused as hell. I loved everything about it...it was just so confusing and so twisted and weird, it was hard not to love it. All of the actors were phenominal, and no one could have done a better job...This is one of my favorites of the year...it deserves an ocar.'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "with open(\"data/imdb_train.json\") as f:\n",
    "    data=json.load(f)\n",
    "random.shuffle(data)\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This film was just absolutly brilliant. It actually made me think. During the whole movie I was confused as hell. I loved everything about it...it was just so confusing and so twisted and weird, it was hard not to love it. All of the actors were phenominal, and no one could have done a better job...This is one of my favorites of the year...it deserves an ocar.']\n",
      "['pos']\n"
     ]
    }
   ],
   "source": [
    "texts=[one_example[\"text\"] for one_example in data]\n",
    "labels=[one_example[\"class\"] for one_example in data]\n",
    "print(texts[:1])\n",
    "print(labels[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy\n",
    "analyzer=CountVectorizer(lowercase=True).build_analyzer() # includes tokenizer and preprocessing\n",
    "with open(\"imdb_harj.txt\", \"wt\") as f:\n",
    "    for text in texts:\n",
    "        words=analyzer(text)\n",
    "        doc=\" \".join(words)\n",
    "        print(doc,file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sen jälkeen terminaalissa (avaa uusi täbi, cntrl+shift t):  git clone https://github.com/tmikolov/word2vec.git\n",
    "#terminaalissa word2vec sisällä: make\n",
    "#./word2vec\n",
    "#esimerkki: ./word2vec -train ../imdb_harj.txt -output vec.txt -size 200 -window 5 -sample 1e-4 -negative 5 -hs 0 -binary 0 -cbow 1\n",
    "#sen jälkeen jupyteriin: w2v similarity kokeilut\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
